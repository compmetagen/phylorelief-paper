#! /usr/bin/env python

## This code is written by Davide Albanese, <davide.albanese@fmach.it>
## <davide.albanese@gmail.com>
## Copyright (C) 2014 Fondazione Edmund Mach
## Copyright (C) 2014 Davide Albanese

## This program is free software: you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation, either version 3 of the License, or
## (at your option) any later version.

## This program is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.

## You should have received a copy of the GNU General Public License
## along with this program.  If not, see <http://www.gnu.org/licenses/>.


from __future__ import division
import argparse
import csv
import os
import sys

import numpy as np
import scipy as sp
import pandas as pd
import dendropy

from sklearn.cross_validation import StratifiedShuffleSplit
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier

from phylorelief import KCCC_discrete, import_otutable, import_sampledata


usage = """%(prog)s otu_table sample_data target
"""

description = """Random Forest without feature selection.
"""

epilog = """Example:

    $ ml_randomforest_nosel otu_table.txt sample_data.txt Status

Authors:
    Davide Albanese <davide.albanese@fmach.it>
    Claudio Donati <claudio.donati@fmach.it>

Fondazione Edmund Mach, 2013
"""

parser = argparse.ArgumentParser(
    usage=usage, description=description,
    formatter_class=argparse.RawDescriptionHelpFormatter,
    epilog=epilog)

parser.add_argument('otu_table',
                    help="an OTU table file (containing the number of "
                    "sequences observed in each OTU for each sample) in "
                    "tab-delimited format")
parser.add_argument('sample_data',
                    help="a tab-delimited file containing sample information "
                    "and metadata")
parser.add_argument('target',
                    help="sample_data column to be used as class label")
parser.add_argument('-o', '--output-file', default="out.txt",
                    help="output file (default %(default)s)")
args = parser.parse_args()


def import_data(otutable_filename, sampledata_filename):
    otutable = import_otutable(otutable_filename)
    sampledata = import_sampledata(sampledata_filename)

    # otu table pruning
    otutable = otutable.loc[otutable.sum(axis=1) > 0]
    
    # align otutable and sampledata
    otutable = otutable.loc[:, sampledata.index]

    return otutable, sampledata


otu_table, sample_data = import_data(args.otu_table, args.sample_data)

try:
    target = sample_data[args.target]
except KeyError:
    sys.stderr.write("target %s is not in the sample table")
    exit(1)
    
classifier = RandomForestClassifier(n_estimators=500, random_state=1)
cv = StratifiedShuffleSplit(target.values, n_iter=10, test_size=0.25,
                            random_state=1)
le = LabelEncoder()
kccc = np.empty(len(cv), dtype=np.float)
for i, (train_index, test_index) in enumerate(cv):

    sys.stdout.write('\r')
    sys.stdout.write("%d%%" % int(((i+1)/len(cv))*100))
    sys.stdout.flush()

    # train and test data
    otu_table_train = otu_table.iloc[:, train_index]
    otu_table_test = otu_table.iloc[:, test_index]
    target_train = target.iloc[train_index]
    target_test =  target.iloc[test_index]

    # prepare for scikit-learn
    x_train = otu_table_train.T.values
    x_test = otu_table_test.T.values
    y_train = target_train.values
    y_test = target_test.values
    le.fit(y_train)
    y_train = le.transform(y_train)
    y_test = le.transform(y_test)

    # learn the model and test
    classifier.fit(x_train, y_train)
    y_true, y_pred = y_test, classifier.predict(x_test)
    kccc[i] = KCCC_discrete(y_true, y_pred)

kccc_mean, kccc_sem = sp.mean(kccc, axis=0), sp.stats.sem(kccc)

# write the output file
fout = open(args.output_file, 'w')
fout.write("%.3f\t%.3f\n" % (kccc_mean, kccc_sem))
fout.write('\t'.join(["%.3f" % elem for elem in kccc]) + '\n')
fout.close()

