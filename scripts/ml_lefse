#! /usr/bin/env python

## This code is written by Davide Albanese, <davide.albanese@fmach.it>
## <davide.albanese@gmail.com>
## Copyright (C) 2014 Fondazione Edmund Mach
## Copyright (C) 2014 Davide Albanese

## This program is free software: you can redistribute it and/or modify
## it under the terms of the GNU General Public License as published by
## the Free Software Foundation, either version 3 of the License, or
## (at your option) any later version.

## This program is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
## GNU General Public License for more details.

## You should have received a copy of the GNU General Public License
## along with this program.  If not, see <http://www.gnu.org/licenses/>.


from __future__ import division
import argparse
import csv
import os
import sys
import subprocess

import numpy as np
import scipy as sp
import pandas as pd
import dendropy

from sklearn.cross_validation import StratifiedShuffleSplit
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestClassifier

from phylorelief import KCCC_discrete, import_otutable, import_sampledata

lefse_path = "path-to-lefse-folder"


usage = """%(prog)s otu_table sample_data target [options]
"""

description = """LEfSe with Random Forest.
"""

epilog = """Example:

    $ ml_lefse otu_table.txt tree.tre sample_data.txt Status

Authors:
    Davide Albanese <davide.albanese@fmach.it>
    Claudio Donati <claudio.donati@fmach.it>

Fondazione Edmund Mach, 2014
"""

parser = argparse.ArgumentParser(
    usage=usage, description=description,
    formatter_class=argparse.RawDescriptionHelpFormatter,
    epilog=epilog)

parser.add_argument('otu_table',
                    help="an OTU table file (containing the number of "
                    "sequences observed in each OTU for each sample) in "
                    "tab-delimited format")
parser.add_argument('sample_data',
                    help="a tab-delimited file containing sample information "
                    "and metadata")
parser.add_argument('target',
                    help="sample_data column to be used as class label")
parser.add_argument('-o', '--output-file', default="out.txt",
                    help="output file (default %(default)s)")
args = parser.parse_args()


def import_data(otutable_filename, sampledata_filename):
    otutable = import_otutable(otutable_filename)
    sampledata = import_sampledata(sampledata_filename)
    print otutable
    print sampledata
    
    # otu table pruning
    otutable = otutable.loc[otutable.sum(axis=1) > 0]
    
    # align otutable and sampledata
    otutable = otutable.loc[:, sampledata.index]

    return otutable, sampledata


def lefse(otu_table, target):
    out_lefse = pd.concat([pd.DataFrame(target).T, otu_table])
    out_lefse.to_csv("train_lefse.txt", '\t', header=False, index=True)

    cmd = [os.path.join(lefse_path, "format_input.py"), "train_lefse.txt",
           "train_lefse.in", "-c", "1", "-s", "-1", "-u", "-1", "-o", "1000000"]
    proc = subprocess.Popen(cmd, stdout=sys.stdout, stderr=subprocess.PIPE)
    _, out_stderr = proc.communicate()
    if proc.returncode:
        raise Exception(out_stderr)

    cmd = [os.path.join(lefse_path, "run_lefse.py"), "train_lefse.in",
           "train_lefse.res", "-o", "test.txt"]
    proc = subprocess.Popen(cmd, stdout=sys.stdout, stderr=subprocess.PIPE)
    _, out_stderr = proc.communicate()
    if proc.returncode:
        raise Exception(out_stderr)

    lefse_res = pd.read_csv("train_lefse.res", sep='\t', header=None, index_col=False)
    selected = lefse_res.loc[lefse_res[2].notnull(), 0]

    return selected
    

otu_table, sample_data = import_data(args.otu_table, args.sample_data)

try:
    target = sample_data[args.target]
except KeyError:
    sys.stderr.write("target %s is not in the sample table")
    exit(1)

classifier = RandomForestClassifier(n_estimators=500, random_state=1)
cv = StratifiedShuffleSplit(target.values, n_iter=10, test_size=0.25,
                            random_state=1)
le = LabelEncoder()
kccc = np.empty(len(cv), dtype=np.float)
for i, (train_index, test_index) in enumerate(cv):

    sys.stdout.write('\r')
    sys.stdout.write("%d%%" % int(((i+1)/len(cv))*100))
    sys.stdout.flush()

    # train and test data
    otu_table_train = otu_table.iloc[:, train_index]
    otu_table_test = otu_table.iloc[:, test_index]
    target_train = target.iloc[train_index]
    target_test = target.iloc[test_index]

    # feature selection with lefse
    selected = lefse(otu_table_train, target_train)

    # filter OTU table with the selected OTUs
    otu_table_train = otu_table_train.loc[selected]
    otu_table_test = otu_table_test.loc[selected]

    # prepare for scikit-learn
    x_train = otu_table_train.T.values
    y_train = target_train.values
    x_test = otu_table_test.T.values
    y_test = target_test.values
    le.fit(y_train)
    y_train = le.transform(y_train)
    y_test = le.transform(y_test)

    # learn the model and test
    classifier.fit(x_train, y_train)
    y_true, y_pred = y_test, classifier.predict(x_test)
    kccc[i] = KCCC_discrete(y_true, y_pred)

kccc_mean, kccc_sem = sp.mean(kccc), sp.stats.sem(kccc)

# perform the feature selection on the entire dataset
selected = lefse(otu_table, target)

# write the output file
fout = open(args.output_file, 'w')
fout.write("%.3f\t%.3f\n" % (kccc_mean, kccc_sem))
fout.write('\t'.join(["%.3f" % elem for elem in kccc]) + '\n')
pd.Series(selected).to_csv(fout, index=False)
fout.close()
